{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obstacle_tower_env import ObstacleTowerEnv\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class EncoderNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderNetwork,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv4 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        print(\"dimesions of y in encoder is \",y)\n",
    "        y= y.flatten(start_dim=1)\n",
    "    \n",
    "\n",
    "\n",
    "class InverseNetowrk(nn.Module):\n",
    "    def __init__(self,no_actions):\n",
    "        super(InverseNetowrk,self).__init__()\n",
    "        self.linear_layerOne = nn.Linear(576,100)\n",
    "        self.linear_layerTwo = nn.Linear(100,no_actions)\n",
    "\n",
    "    def forward(self,state1,state2):\n",
    "        x = torch.cat((state1,state2),dim=1)\n",
    "        y = F.relu(self.linear_layerOne(x))\n",
    "        y = self.linear_layerTwo(y)\n",
    "        y = F.softmax(y,dim=1)\n",
    "        \n",
    "        return y\n",
    "\n",
    "class ForwardNetwork(nn.Module):\n",
    "    def __init__(self,no_actions):\n",
    "        super(ForwardNetwork,self).__init__()\n",
    "        self.linear_layerOne = nn.Linear(576,256)\n",
    "        self.linear_layerTwo = nn.Linear(256,no_actions)\n",
    "\n",
    "\n",
    "    def forward(self,state,action):\n",
    "        action_ = torch.zeros(action.shape[0],12)\n",
    "        indices = torch.stack((torch.arange(action.shape[0]),action.squeeze()),dim=0)\n",
    "        indices = indices.tolist()\n",
    "        action_[indices] = 1.\n",
    "        x = torch.cat((state,action_),dim=1)\n",
    "        y = F.relu(self.linear_layerOne(x))\n",
    "        y = self.linear_layerTwo(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,no_actions):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.conv4 = nn.Conv2d(32,32,kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.linear_layerOne = nn.Linear(288,100)\n",
    "        self.linear_layerTwo = nn.Linear(100,no_actions)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = F.relu(self.conv2(y))\n",
    "        y = F.relu(self.conv3(y))\n",
    "        y = F.relu(self.conv4(y))\n",
    "        y= y.flatten(start_dim=2)\n",
    "        y = y.view(y.shape[0],-1,32)\n",
    "        y= y.flatten(start_dim=1)\n",
    "        y = F.relu(self.linear_layerOne(y))\n",
    "        y = self.linear_layerTwo(y)\n",
    "        return y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from secrets import choice\n",
    "\n",
    "class ExperienceRelayMemory:\n",
    "    def __init__(self,N=500,batch_size=100):\n",
    "        self.N = N\n",
    "        self.batch_size =batch_size\n",
    "        self.memory = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def add_memory(self,state1,action,reward,state2):\n",
    "        self.counter += 1\n",
    "        if self.counter % 500 == 0:\n",
    "            self.shuffle_memory()\n",
    "\n",
    "        if len(self.memory) < self.N:\n",
    "            self.memory.append((state1,action,reward,state2))\n",
    "        else:\n",
    "            rand_idx  = np.random.randint(0,self.N-1)\n",
    "            self.memory[rand_idx] = (state1,action,reward,state2)\n",
    "\n",
    "    def shuffle_memory(self):\n",
    "        shuffle(self.memory)\n",
    "\n",
    "    def get_batch(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            batch_size = len(self.memory)\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "        if len(self.memory)< 1:\n",
    "            print(\"Errror Memory is empty\")\n",
    "            return None\n",
    "\n",
    "        index =  np.random.choice(np.arange(len(self.memory)),batch_size,replace=False)\n",
    "        batch = [self.memory[i] for i in index ]\n",
    "        state1_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
    "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
    "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
    "        state2_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
    "\n",
    "        return state1_batch,action_batch,reward_batch,state2_batch\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':150,\n",
    "    'beta':0.2,\n",
    "    'lambda':0.1,\n",
    "    'eta' : 1.0,\n",
    "    'gamma':0.2,\n",
    "    'max_episode_length': 100,\n",
    "    'min_progress':15,\n",
    "    'action_repeats':6,\n",
    "    'frames_per_second':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = ExperienceRelayMemory(N=1000,batch_size=params['batch_size'])\n",
    "Qmodel = NeuralNetwork()\n",
    "encoder = EncoderNetwork()\n",
    "forward_model = ForwardNetwork()\n",
    "inverse_model =InverseNetowrk()\n",
    "\n",
    "forward_loss = nn.MSELoss(reduction='none')\n",
    "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "qloss = nn.MSELoss()\n",
    "\n",
    "all_model_params = list(Qmodel.parameters()+list(encoder.parameters()))\n",
    "all_model_params += list(forward_model.parameters()) + list(inverse_model.parameters())\n",
    "\n",
    "\n",
    "opt = optim.Adam(lr=0.001,params=all_model_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(q_loss,inverse_loss,forward_loss):\n",
    "    loss_ = (1-params['beta']) * inverse_loss\n",
    "    loss_ += params['beta'] * forward_loss\n",
    "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
    "    loss = loss_ + params['lambda']* q_loss\n",
    "\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
